Reinforcement Learning excerpt from 

https://www.nets-vs-automata.net/rl.html


Recent Updates: 
1) Removed Actor's unnatural patternNetwork to start. 

Simplified to basic Actor-Critic.

The agent now has 16 extra output nodes in the basic action network that correspond to 16 possible 2x2 write patterns.


To do:

Practical approach:
Log human play -> Supervised Learning Weight Init. from human play -> Final stage of RL (Like Alpha Go approach of training on top Go players)




The Recurse Center asks us to program at the edge...

“The Edge... There is no honest way to explain it because the only people who really know where it is are the ones who have gone over. The others-the living-are those who pushed their control as far as they felt they could handle it, and then pulled back, or slowed down, or did whatever they had to when it came time to choose between Now and Later. But the edge is still Out there.”