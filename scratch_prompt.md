I am trying to explore new approaches for learning sequences of moves in a cellular automaton game. One of the games asks the agent (or user in manual mode) to create a pattern within n steps. The agent can move left, right, up, down, or do nothing. It can also choose to write one of 16 2x2 bit patterns. I'm using a convNet architecture which is good for analyzing the point-in-time state, but I don't think it is learning sequences of good discrete moves. I'm wondering if I need a neural-symbolic search approach. For instance, it seems very hard for the agent to currently learn the sequence F (write [[1, 1], [1,1]] ), Left, Up, E (write [[1, 1], [1,0]]), and then Pass for the remainder of steps until the end of the episode to generate the target pattern in the attached picture. Please see the attached diagram of learning progress after 4000+ episodes of 10 steps and the source code. (The command line code run was "uv run rl_ca.py train --reward pattern --pattern-file custom_pattern_12x12_medium.npy --live-plot 25 --episodes 5000") Can you change the net architecture(s) to have an LSTM head after the ConvNet? Please capture the  entire convnet feature state, not a lossy compressed  vector of 128 nodes.
Please do not drop any functionality. Please generate the new functions and class objects I need to make the updates. Please write complete functions that I can use as a drop-and-replace solution for existing functions.

I am trying to explore new approaches for learning sequences of moves in a cellular automaton game. One of the games asks the agent (or user in manual mode) to create a pattern within n steps. The agent can move left, right, up, down, or do nothing. It can also choose to write one of 16 2x2 bit patterns. I'm using a convNet architecture which is good for analyzing the point-in-time state, but I don't think it is learning sequences of good discrete moves. I'm wondering if I need a neural-symbolic search approach or just a symbolic. For instance, it seems very hard for the agent to currently learn the sequence F (write [[1, 1], [1,1]] ), Left, Up, E (write [[1, 1], [1,0]]), and then Pass/Move Left/Right/Up/Down for the remainder of steps until the end of the episode to generate the target pattern in the attached picture. Please see the attached diagram of learning progress after 4000+ episodes of 10 steps and the source code. 

I'd like to update my code to make it an evolutionary algorithm. The code should generate the cellular automaton state at the end of n, say 10, action-and-update steps and then measure their fitness (ability to match the target pattern). Top performing action sequences should be selected and their actions should be mutated in the next round. Please make these changes and update the diagrams accordingly to show new helpful information for this type of training . These changes should simplify the code a lot, but please make sure to keep the command line tooling, the matplotlib graphing, and as much of the relevant peripheral code as necessary. 